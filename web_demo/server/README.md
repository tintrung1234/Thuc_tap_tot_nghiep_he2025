# üìå Blog Search Backend

This is the backend for a blog search application with intelligent search capabilities powered by Retrieval-Augmented Generation (RAG) using Chroma vector database and Ollama LLM. Built with Node.js, Express, and Mongoose, it integrates JWT authentication, Cloudinary for image uploads, and a Python ETL pipeline for indexing blog posts into Chroma.

## üöÄ Technologies Used

- **Node.js**: JavaScript runtime for server-side logic.
- **Express**: Web framework for building RESTful APIs.
- **Mongoose**: ODM for MongoDB to manage data models (Post, Category, Tag, User).
- **Multer**: Middleware for handling file uploads (e.g., post images).
- **JWT**: JSON Web Token for user authentication.
- **Cloudinary**: Cloud service for storing and serving post images.
- **ChromaDB**: Vector database for storing and querying blog post embeddings.
- **Ollama**: Local LLM (LLaMA3) for generating natural language answers in RAG.
- **@xenova/transformers**: Embedding model for query vectorization.
- **LangChain**: Framework for building RAG pipeline.
- **Axios**: HTTP client for communicating with ETL API.
- **CORS**: Middleware for enabling cross-origin requests.

## üìÇ Project Structure

```
backend/
‚îú‚îÄ‚îÄ config/                     # Configuration files (e.g., database connection)
‚îú‚îÄ‚îÄ controllers/                # API controllers for handling requests
‚îú‚îÄ‚îÄ middlewares/                # Middleware for authentication and other logic
‚îú‚îÄ‚îÄ models/                     # Mongoose schemas (Post, User, etc.)
‚îú‚îÄ‚îÄ node_modules/               # Auto-generated dependencies (ignored)
‚îú‚îÄ‚îÄ routes/                     # API route definitions
‚îú‚îÄ‚îÄ services/                   # Business logic (e.g., RAG search)
‚îú‚îÄ‚îÄ uploads/                    # Temporary storage for file uploads (ignored)
‚îú‚îÄ‚îÄ .env                        # Environment variables (ignored)
‚îú‚îÄ‚îÄ .gitignore                  # Git ignore file
‚îú‚îÄ‚îÄ README.md                   # Project documentation
‚îú‚îÄ‚îÄ app.js                      # Express app entry point
‚îú‚îÄ‚îÄ package-lock.json           # Lock file for dependencies
‚îú‚îÄ‚îÄ package.json                # Project metadata and dependencies
‚îî‚îÄ‚îÄ server.js                   # Alternative server entry point (if used)
```

## ‚öôÔ∏è Setup and Installation

1. **Prerequisites** üîß:

   - Node.js (v16 or higher)
   - MongoDB Atlas (accessible via `MONGODB_URI`)
   - Chroma server (running at `CHROMA_HOST:CHROMA_PORT`)
   - Ollama server (running at `OLLAMA_BASE_URL` with `OLLAMA_MODEL`)
   - Python ETL server (running at `ETL_API_URL`)
   - Cloudinary account for image uploads

2. **Install Dependencies** üì¶:

   ```bash
   cd client
   npm install
   ```

3. **MongoDB Setup** üóÑÔ∏è:
   - Connect to MongoDB Atlas using `MONGODB_URI`.
   - Example data for `blog_db.posts`:
     ```javascript
     use blog_db;
     db.posts.insertOne({
       uid: new ObjectId(),
       title: "Gi·ªõi thi·ªáu H√† N·ªôi",
       slug: "gioi-thieu-ha-noi",
       description: "Th·ªß ƒë√¥ Vi·ªát Nam",
       content: "<p>H√† N·ªôi l√† th·ªß ƒë√¥ c·ªßa Vi·ªát Nam. Th√†nh ph·ªë n√†y c√≥ l·ªãch s·ª≠ h∆°n 1000 nƒÉm.</p>",
       imageUrl: "https://res.cloudinary.com/daeorkmlh/image/upload/...",
       category: new ObjectId(),
       tags: [],
       status: "published",
       views: 0,
       isDeleted: false
     });
     ```

## üåç Environment Variables

Create a `.env` file in the `client` directory with the following variables:

```env
MONGODB_URI=
JWT_SECRET=
CLOUDINARY_CLOUD_NAME=
CLOUDINARY_API_KEY=
CLOUDINARY_API_SECRET=
PORT=
CHROMA_HOST=
CHROMA_PORT=
CHROMA_SSL=
COLLECTION_NAME=
OLLAMA_BASE_URL=
OLLAMA_MODEL=
EMBED_MODEL=
ETL_API_URL=
```

- **MONGODB_URI**: MongoDB Atlas connection string (replace `<password>` with your password).
- **JWT_SECRET**: Secret key for signing JWT tokens.
- **CLOUDINARY_CLOUD_NAME**: Cloudinary cloud name for image storage.
- **CLOUDINARY_API_KEY**: Cloudinary API key.
- **CLOUDINARY_API_SECRET**: Cloudinary API secret.
- **PORT**: Port for the Express server.
- **CHROMA_HOST**: Chroma server hostname.
- **CHROMA_PORT**: Chroma server port.
- **CHROMA_SSL**: Enable SSL for Chroma (true/false).
- **COLLECTION_NAME**: Chroma collection name for blog post embeddings.
- **OLLAMA_BASE_URL**: Ollama server URL for LLM.
- **OLLAMA_MODEL**: Ollama model name (e.g., llama3).
- **EMBED_MODEL**: Sentence-Transformers model for embeddings.
- **ETL_API_URL**: Python ETL API endpoint for indexing posts.

## üèÉ Running the Application

1. **Start MongoDB Atlas** ‚òÅÔ∏è:

   - Ensure `MONGODB_URI` is accessible (configured in MongoDB Atlas).

2. **Start Chroma Server** üìä:

   ```bash
   cd ../chroma_server
   chroma run --path ./chroma-data --port 8000
   ```

3. **Start Ollama** ü§ñ:

   ```bash
   ollama run llama3
   ```

4. **Start ETL API** üõ†Ô∏è:

   ```bash
   cd ../chroma_server
   python -m etl.main
   ```

5. **Start Backend** üöÄ:

   ```bash
   cd server
   node server.js
   ```

   - Server runs at `http://localhost:3000`.

6. **Start Frontend** (optional) üåê:
   ```bash
   cd ../client
   npm run dev
   ```

## üîê Authentication

- The backend uses JWT for authentication. Protected endpoints (e.g., `/api/posts`) require a Bearer token in the `Authorization` header.
- **Login**:
  - Endpoint: `POST /api/users/login`
  - Request:
    ```json
    {
      "email": "user@example.com",
      "password": "password123"
    }
    ```
  - Response:
    ```json
    {
      "token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."
    }
    ```
- **Usage**: Include token in requests:
  ```bash
  curl -H "Authorization: Bearer <token>" http://localhost:3000/api/posts
  ```

## üîç API Endpoints Feature

### POST `/api/search`

- **Description**: Performs intelligent search using RAG (Retrieval-Augmented Generation).
- **Request Body**:
  ```json
  {
    "query": "·∫®m th·ª±c H√† N·ªôi l√† g√¨?"
  }
  ```
- **Response**:
  ```json
  {
    "chunks": [
      {
        "content": "Ph·ªü l√† m√≥n ƒÉn n·ªïi ti·∫øng ·ªü H√† N·ªôi.",
        "metadata": {
          "post_id": "123",
          "title": "·∫®m th·ª±c H√† N·ªôi",
          "url": "/posts/am-thuc-ha-noi",
          "chunk_index": 0,
          "char_start": 0,
          "char_end": 50,
          "hash": "abc123..."
        }
      }
    ],
    "answer": "Ph·ªü l√† m√≥n ƒÉn n·ªïi ti·∫øng nh·∫•t ·ªü H√† N·ªôi, th∆∞·ªùng ƒë∆∞·ª£c ƒÉn v√†o b·ªØa s√°ng."
  }
  ```

### GET `/api/posts`

- **Description**: Fetches all published posts with optional filters.
- **Query Parameters**:
  - `q`: Search query (searches title, description, content).
  - `category`: Category ID.
  - `tags`: Tag ID.
  - `status`: Post status (e.g., "published").
  - `isDeleted`: Filter deleted posts (true/false).
- **Example**:
  ```
  GET /api/posts?status=published&isDeleted=false
  ```
- **Response**:
  ```json
  [
    {
      "_id": "123",
      "title": "Gi·ªõi thi·ªáu H√† N·ªôi",
      "slug": "gioi-thieu-ha-noi",
      "description": "Th·ªß ƒë√¥ Vi·ªát Nam",
      "content": "<p>H√† N·ªôi l√† th·ªß ƒë√¥ c·ªßa Vi·ªát Nam...</p>",
      "imageUrl": "https://res.cloudinary.com/daeorkmlh/image/upload/...",
      "category": {},
      "tags": [],
      "status": "published",
      "isDeleted": false
    }
  ]
  ```

### POST `/api/posts`

- **Description**: Creates a new post and triggers ETL (upsert to Chroma). Requires authentication.
- **Request Body** (multipart/form-data for image):
  ```json
  {
    "uid": "user_id",
    "title": "·∫®m th·ª±c H√† N·ªôi",
    "slug": "am-thuc-ha-noi",
    "description": "M√≥n ngon H√† N·ªôi",
    "content": "<p>Ph·ªü l√† m√≥n ƒÉn n·ªïi ti·∫øng ·ªü H√† N·ªôi.</p>",
    "category": "category_id",
    "tags": [],
    "status": "published",
    "image": "<file>"
  }
  ```
- **Headers**:
  ```
  Authorization: Bearer <token>
  ```

## üõ†Ô∏è ETL Integration

- The backend communicates with a Python ETL pipeline (running at `ETL_API_URL`).
- On post save (`Post.js` middleware), it sends post data to the ETL API for indexing into Chroma:
  - Action: `upsert` for published posts, `delete` for others.
- To re-run ETL for all posts:
  ```bash
  cd ../chroma_server
  python return_etl.py
  ```

## ü§ñ RAG Search

- The `/api/search` endpoint uses a Retrieval-Augmented Generation (RAG) pipeline:
  1. **Embedding**: Query is embedded using `EMBED_MODEL` (Xenova/paraphrase-multilingual-MiniLM-L12-v2).
  2. **Retrieval**: Top-3 chunks are retrieved from Chroma (`COLLECTION_NAME`).
  3. **Generation**: Ollama (`OLLAMA_MODEL`) generates a natural language answer based on chunks.
- The response includes both chunks (for context) and the LLM-generated answer.

## üêû Debugging

- **MongoDB**: Verify `MONGODB_URI` connection with MongoDB Atlas (check Network Access/Database Access).
- **Chroma**: Check server status (`curl http://localhost:8000/api/v1/collections`).
- **Ollama**: Test LLM (`curl http://localhost:11434/api/generate -d '{"model":"llama3","prompt":"Test"}'`).
- **ETL API**: Test endpoint (`curl -X POST http://localhost:5001/etl/process -H "Content-Type: application/json" -d '{"action":"upsert","post":{"post_id":"123","title":"Test","slug":"test","content":"Hello"}}'`).
- **JWT**: Ensure valid token (`JWT_SECRET`) for protected routes.
- **Cloudinary**: Verify `CLOUDINARY_*` credentials for image uploads.
- **Logs**: Check console for errors in `server.js` or `etl/main.py`.

## üîÆ Future Improvements

- Add rate limiting for API endpoints.
- Implement RabbitMQ for async ETL processing.
- Optimize RAG with custom prompt templates.
- Deploy with Docker Compose for production.

## üìú License

MIT License ¬© 2025
